# Flashcards – NIST AI RMF: Generative AI Risk Categories

---

**Q:** What is confabulation in Generative AI?  
**A:** When the AI produces false or misleading information that sounds plausible.

---

**Q:** What is model inversion?  
**A:** A risk where attackers deduce sensitive training data by analyzing model outputs.

---

**Q:** Why is Human-AI configuration a risk?  
**A:** Misalignment, over-reliance, or unclear responsibility between human and machine can lead to misuse or harm.

---

**Q:** What’s a real-world example of CBRN Information risk?  
**A:** An AI chatbot generating step-by-step instructions for building harmful chemical agents.

---

**Q:** How can GAI lead to IP concerns?  
**A:** It may recreate copyrighted content or leak trade secrets.

---

**Q:** What is model evasion?  
**A:** When adversaries manipulate inputs to fool the model into giving incorrect or harmful outputs.

---

**Q:** What is the risk of malicious use?  
**A:** GAI can be used to generate malware, phishing emails, or misinformation.

---

**Q:** How does bias show up in GAI?  
**A:** It may replicate or amplify societal biases in training data.

---

**Q:** What is the danger of model theft?  
**A:** Someone could copy or clone the model, exposing proprietary information or enabling abuse.

---

**Q:** What is model misuse?  
**A:** Unintentional harmful use due to misunderstanding of model limitations or lack of safeguards.
