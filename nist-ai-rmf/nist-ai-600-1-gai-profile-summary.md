# NIST AI RMF Generative AI Profile ‚Äì Study Summary

**Document:** NIST AI 600-1, *Generative Artificial Intelligence Profile*  
**Published:** July 2024  
**Purpose:** A companion resource to the NIST AI RMF 1.0, providing guidance on identifying and managing risks specific to Generative AI (GAI).

---

## üìå Background

The Generative AI Profile supports the safe, secure, and trustworthy use of generative AI systems. It responds to concerns raised in **Executive Order 14110** by highlighting key risks and suggesting governance practices aligned with the AI Risk Management Framework (AI RMF).

---

## üß≠ AI RMF Core Functions

1. **Map** ‚Äì Understand the context and intended purpose of the AI system.  
2. **Measure** ‚Äì Assess risks and trustworthiness characteristics.  
3. **Manage** ‚Äì Prioritize and act on risks to minimize negative impacts.  
4. **Govern** ‚Äì Establish organizational policies and processes for risk oversight.

---

## ‚ö†Ô∏è Risk Categories Unique to or Exacerbated by Generative AI

| Risk Category               | Description |
|----------------------------|-------------|
| **CBRN Information**       | GAI may make it easier to access information about chemical, biological, radiological, and nuclear threats. |
| **Data Privacy**           | GAI can generate or leak personal data, raising privacy risks. |
| **Confabulation**          | GAI may generate believable but false or misleading content. |
| **Human-AI Configuration** | Users may overly trust or misuse GAI outputs, or misalign goals. |
| **Intellectual Property**  | GAI can produce content that may infringe copyrights or IP rights. |
| **Obscene/Abusive Content**| Harmful, hateful, or inappropriate outputs pose reputational and societal risk. |
| **Model Inversion**        | Attackers may infer training data from model outputs. |
| **Model Theft**            | Intellectual property risks related to unauthorized access or replication. |
| **Model Evasion**          | Prompt injection and adversarial attacks can manipulate GAI behavior. |
| **Model Bias**             | GAI can reflect or amplify harmful societal biases. |
| **Malicious Use**          | GAI can be exploited to create malware, phishing content, or disinformation. |
| **Misuse**                 | Unintentional but harmful use due to lack of understanding or guardrails. |

---

## ‚úÖ Suggested Risk Management Actions

### Govern
- Establish oversight processes and policies for GAI development and use.
- Clarify accountability, transparency, and review mechanisms.

### Map
- Define the intended use, users, and potential misuse scenarios.
- Document and understand training data and model limitations.

### Measure
- Conduct privacy impact assessments.
- Measure accuracy, fairness, robustness, and bias.
- Test for confabulation and evasion vulnerabilities.

### Manage
- Apply safeguards like access control and monitoring.
- Use retrieval-augmented generation (RAG) to ground outputs in verifiable facts.
- Develop response plans for harmful or unexpected outputs.

---

## üîç Appendix A Highlights ‚Äì Key GAI Considerations

- AI models must be evaluated in real-world contexts.
- Shared responsibility: Developers, deployers, and users each have roles in mitigating risk.
- Emphasis on transparency, documentation, and evaluation to reduce risk of harm.

---

## üß† Summary

This profile supports the responsible use of generative AI by:
- Identifying key risk areas specific to GAI.
- Mapping those risks to the AI RMF.
- Providing actionable suggestions that organizations can tailor to their risk tolerance and regulatory needs.
